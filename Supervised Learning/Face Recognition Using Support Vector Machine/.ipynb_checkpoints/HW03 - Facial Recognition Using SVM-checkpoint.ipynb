{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Homework 3 - Facial Recognition Using SVM\n",
    "### Group Members:  \n",
    "Catherine Suh      304321581<br>\n",
    "Carlos Hernandes   201943215<br>\n",
    "Miguel Martinez    220903291"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# import libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# for drawing images on screen\n",
    "import matplotlib.image as mpimg\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib\tinline\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parts A and B\n",
    "Read in label from provided file. Read images one by one and put into flat numpy array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# read labels\n",
    "y = pd.read_csv('Face/label.csv', squeeze=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(400, 4096)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 186.,  183.,  179., ...,    9.,    3.,    5.],\n",
       "       [ 204.,  198.,  194., ...,  120.,  164.,  167.],\n",
       "       [  86.,   79.,   82., ...,  189.,  185.,  141.],\n",
       "       ..., \n",
       "       [ 163.,  177.,  193., ...,   44.,   48.,   53.],\n",
       "       [ 145.,  147.,  151., ...,  132.,  114.,  117.],\n",
       "       [  91.,   74.,   66., ...,   75.,   44.,   46.]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# empty np array to hold features matrix\n",
    "features = np.empty([0,4096])\n",
    "\n",
    "pathToImage = 'Face/'\n",
    "\n",
    "# build features matrix\n",
    "for i in range(400):\n",
    "    \n",
    "    # read image\n",
    "    img = mpimg.imread(pathToImage + str(i) + '.jpg')\n",
    "    img = img.flatten().reshape(1,4096)\n",
    "    \n",
    "    features = np.concatenate([features,img])\n",
    "\n",
    "print(features.shape)\n",
    "features\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part C\n",
    "Normalize features with zero mean and unit std. deviation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.37649641,  1.11885303,  0.79610373, ..., -1.17094622,\n",
       "        -1.24726506, -1.21711982],\n",
       "       [ 1.68113398,  1.3654141 ,  1.03570156, ...,  0.68710075,\n",
       "         1.48558299,  1.58234648],\n",
       "       [-0.31593455, -0.59063704, -0.75329558, ...,  1.84210291,\n",
       "         1.84204144,  1.13304942],\n",
       "       ..., \n",
       "       [ 0.98723729,  1.02022861,  1.01972837, ..., -0.58507555,\n",
       "        -0.48342554, -0.38764832],\n",
       "       [ 0.68259971,  0.52710647,  0.34885444, ...,  0.88797069,\n",
       "         0.63687242,  0.71831368],\n",
       "       [-0.231313  , -0.67282406, -1.0088666 , ..., -0.06616154,\n",
       "        -0.55132239, -0.50861291]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocessing.scale(features, copy=False)\n",
    "features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part D\n",
    "Train Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# train test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, y, test_size=0.25, random_state=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part E & F\n",
    "PCA to remove redundancies and reduce amount of data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SVM Without PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.86\n"
     ]
    }
   ],
   "source": [
    "clf = SVC(C=1, kernel='rbf', gamma=0.0005, random_state=1)\n",
    "clf.fit(X_train, y_train)\n",
    "y_predict_svm = clf.predict(X_test)\n",
    "\n",
    "score_svm = accuracy_score(y_test, y_predict_svm)\n",
    "print(score_svm)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Apply PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training: (300, 50)\n",
      "Testing: (100, 50)\n"
     ]
    }
   ],
   "source": [
    "pca = PCA(n_components=50)\n",
    "pca.fit(X_train)\n",
    "\n",
    "X_train_pca = pca.transform(X_train)\n",
    "X_test_pca = pca.transform(X_test)\n",
    "\n",
    "print('Training:', X_train_pca.shape)\n",
    "print('Testing:',X_test_pca.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SVM With PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.91\n"
     ]
    }
   ],
   "source": [
    "# Accuracy with on PCA \n",
    "clf = SVC(C=1, kernel='rbf', gamma=0.0005, random_state=1)\n",
    "clf.fit(X_train_pca, y_train)\n",
    "y_predict_svm = clf.predict(X_test_pca)\n",
    "\n",
    "score_svm = accuracy_score(y_test, y_predict_svm)\n",
    "print(score_svm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix:\n",
      "[[3 0 0 ..., 0 0 0]\n",
      " [0 3 0 ..., 0 0 0]\n",
      " [0 0 1 ..., 0 0 0]\n",
      " ..., \n",
      " [0 0 0 ..., 0 0 0]\n",
      " [0 0 0 ..., 0 4 0]\n",
      " [0 0 0 ..., 0 0 1]]\n"
     ]
    }
   ],
   "source": [
    "cm_SVM = metrics.confusion_matrix(y_test, y_predict_svm)\n",
    "print(\"Confusion matrix:\")\n",
    "print(cm_SVM)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part G\n",
    "Use GridSearch CV to find best C parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Apply PCA to entire dataset (not using train test split)\n",
    "pca.fit(features)\n",
    "X = pca.transform(features)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': [0.1, 1, 10, 100, 1000.0, 5000.0, 10000.0, 50000.0, 100000.0]} \n",
      "\n",
      "BEST Accuracy: 0.965\n",
      "BEST Number C option: {'C': 10}\n"
     ]
    }
   ],
   "source": [
    "# define a range for the \"number of neurons\" in the hidden layer for a network with 1 hidden layer:\n",
    "c_options = [0.1,1,10,100,1e3,5e3,1e4,5e4,1e5]\n",
    "\n",
    "# create a dictionary for grid parameter:\n",
    "param_grid = dict(C = c_options)\n",
    "print(param_grid,'\\n')\n",
    "\n",
    "# instantiate the model:\n",
    "my_SVM = SVC(kernel='rbf', gamma=0.0005, random_state=1)\n",
    "\n",
    "# create the grid, and define the metric for evaluating the model: \n",
    "grid = GridSearchCV(my_SVM, param_grid, cv=10, scoring='accuracy', n_jobs=8)\n",
    "\n",
    "# fit the grid (start the grid search):\n",
    "grid.fit(X, y)\n",
    "\n",
    "# view the results:\n",
    "#print(grid.cv_results_)\n",
    "\n",
    "# view the best results corresponding to the best structure of ANN:\n",
    "print('BEST Accuracy:', grid.best_score_)\n",
    "print('BEST Number C option:', grid.best_params_)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
