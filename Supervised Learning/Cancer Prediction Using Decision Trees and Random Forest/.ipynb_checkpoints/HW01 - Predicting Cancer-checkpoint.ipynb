{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Homework1 - Cancer Diagnosis Using Machine Learning\n",
    "### Group Members:  \n",
    "Catherine Suh      304321581<br>\n",
    "Carlos Hernandes   201943215<br>\n",
    "Miguel Martinez    220903291"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# import libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.utils import resample\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PART A:\n",
    "Read the dataset file “Cancer.csv” (you should download it from CSNS), and store it in a Pandas DataFrame. Check out the dataset. As you see, the dataset includes 9 numerical features. The last column is the binary label (“1” means it is a malignant cancer, “0” means it is a benign tumor). You will use all 9 features in this homework."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Clump_Thickness</th>\n",
       "      <th>Uniformity_of_Cell_Size</th>\n",
       "      <th>Uniformity_of_Cell_Shape</th>\n",
       "      <th>Marginal_Adhesion</th>\n",
       "      <th>Single_Epithelial_Cell_Size</th>\n",
       "      <th>Bare_Nuclei</th>\n",
       "      <th>Bland_Chromatin</th>\n",
       "      <th>Normal_Nucleoli</th>\n",
       "      <th>Mitoses</th>\n",
       "      <th>Malignant_Cancer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Clump_Thickness  Uniformity_of_Cell_Size  Uniformity_of_Cell_Shape  \\\n",
       "0                5                        1                         1   \n",
       "1                5                        4                         4   \n",
       "2                3                        1                         1   \n",
       "3                6                        8                         8   \n",
       "4                4                        1                         1   \n",
       "\n",
       "   Marginal_Adhesion  Single_Epithelial_Cell_Size  Bare_Nuclei  \\\n",
       "0                  1                            2            1   \n",
       "1                  5                            7           10   \n",
       "2                  1                            2            2   \n",
       "3                  1                            3            4   \n",
       "4                  3                            2            1   \n",
       "\n",
       "   Bland_Chromatin  Normal_Nucleoli  Mitoses  Malignant_Cancer  \n",
       "0                3                1        1                 0  \n",
       "1                3                2        1                 0  \n",
       "2                3                1        1                 0  \n",
       "3                3                7        1                 0  \n",
       "4                3                1        1                 0  "
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# PART A:\n",
    "# Read the dataset file “Cancer.csv” (you should download it from CSNS), and store it in a \n",
    "# Pandas DataFrame. Check out the dataset. As you see, the dataset includes 9 numerical \n",
    "# features. The last column is the binary label (“1” means it is a malignant cancer, “0” means \n",
    "# it is a benign tumor). You will use all 9 features in this homework.\n",
    "\n",
    "cancerData = pd.read_csv('data/Cancer_small.csv')\n",
    "cancerData.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PART B:\n",
    "Use sklearn functions (see class tutorials for details) to split the dataset into testing and training sets with the following parameters: test_size=0.3, random_state=2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "label = 'Malignant_Cancer'\n",
    "\n",
    "# split X and y\n",
    "X = cancerData.drop(label, axis=1)\n",
    "y = cancerData[label]\n",
    "\n",
    "# train test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PART C:\n",
    "Use “Decision Tree Classifier” to predict Cancer based on  the  training/testing datasets \n",
    "that you built in part (b). Then, calculate and report the accuracy of your classifier. Use \n",
    "this command to define your tree: \n",
    "my_DecisionTree = DecisionTreeClassifier(random_state=2)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DTC Score: 0.866666666667\n"
     ]
    }
   ],
   "source": [
    "# instantiate model object\n",
    "my_decisiontree = DecisionTreeClassifier(random_state=2)\n",
    "\n",
    "# fit model\n",
    "my_decisiontree.fit(X_train, y_train)\n",
    "\n",
    "y_predict = my_decisiontree.predict(X_test)\n",
    "\n",
    "score = accuracy_score(y_test, y_predict)\n",
    "\n",
    "print('DTC Score:',score)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# PART D:\n",
    "Now, we want to perform “Bagging” based on 19 “base decision tree classifiers”. \n",
    "Note: you should write your own code to perform Bagging (don’t use scikit-learn functions \n",
    "for Bagging!)\n",
    "To do so, you need to perform bootstrapping first. You can write a “for” loop with loop \n",
    "variable i=0…18.  \n",
    "In each iteration of the loop, you have to:\n",
    "- make a bootstarp sample of the original “Training” Dataset (build in part(b)) with size \n",
    "of  bootstarp_size =  0.8*(Size of  the  original  dataset). You  can  use  the  following \n",
    "command to generate a random bootstrap dataset (“i\" is the variable of the loop, so \n",
    "the random_state changes in each iteration):\n",
    "resample(X_train, n_samples = bootstrap_size , random_state=i , replace = True)\n",
    "- Define and train a new base decision tree classifier on this dataset in each iteration:\n",
    "Base_DecisionTree = DecisionTreeClassifier(random_state=2).\n",
    "- Test “this base classifier” on the original “Testing” Dataset build in part(b), and save \n",
    "the prediction results for all testing samples.\n",
    "- Perform Voting to make the final decision on each data sample based on the votes of \n",
    "all 19 classifiers.\n",
    "Finally, calculate and report the accuracy of your Bagging method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X (150, 9)\n",
      "X_train (105, 9)\n",
      "Bootstrap Size: 84\n",
      "Bagging DTC Score: 0.911111111111\n"
     ]
    }
   ],
   "source": [
    "bootstrap_size = int(.8*X_train.shape[0])\n",
    "\n",
    "print('X', X.shape)\n",
    "print('X_train', X_train.shape)\n",
    "print('Bootstrap Size:', bootstrap_size)\n",
    "\n",
    "# dictionary to hold predictions of all classifiers\n",
    "predictionsForX_Test = {}\n",
    "\n",
    "# each of the 19 DTCs is fitted and predicts on X_test\n",
    "for i in range(0,19):\n",
    "    sampleX = resample(X_train, n_samples = bootstrap_size , random_state=i , replace = True)\n",
    "    sampleY = resample(y_train, n_samples = bootstrap_size , random_state=i , replace = True)\n",
    "    Base_DecisionTree = DecisionTreeClassifier(random_state=2)\n",
    "    Base_DecisionTree.fit(sampleX, sampleY)\n",
    "    \n",
    "    # add np array to dict\n",
    "    predictionsForX_Test[i] = Base_DecisionTree.predict(X_test)\n",
    "\n",
    "\n",
    "# array to hold voted predictions    \n",
    "y_voted_pred = np.empty([X_test.shape[0]])\n",
    "    \n",
    "# voting for each of the 45 testing samples\n",
    "# go through each sample\n",
    "for i in range (X_test.shape[0]):\n",
    "    zero = 0\n",
    "    one = 0\n",
    "    \n",
    "    # go through each Decision Tree Fitted Classifier\n",
    "    for j in range(0,19):\n",
    "        if predictionsForX_Test[j][i] == 0:\n",
    "            zero = zero + 1\n",
    "        else:\n",
    "            one = one + 1\n",
    "    \n",
    "    # prints out voting results for each testing sample\n",
    "    #print(i, zero, one)\n",
    "    \n",
    "    # count votes and take majority\n",
    "    if zero > one:\n",
    "        y_voted_pred[i] = 0\n",
    "    else:\n",
    "        y_voted_pred[i] = 1\n",
    "    \n",
    "score = accuracy_score(y_test, y_voted_pred)\n",
    "\n",
    "print('Bagging DTC Score:',score)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# PART E:\n",
    "Use scikit-learn  “Adaboost” classifier  to  predict  Cancer based  on  the  training/testing \n",
    "datasets  that  you  built  in  part  (b).  Then, calculate and  report  the  accuracy  of  your \n",
    "classifier. Use this command to import and define your classifier: \n",
    "from   sklearn.ensemble   import     AdaBoostClassifier\n",
    "my_RandomForest = \n",
    "my_AdaBoost = AdaBoostClassifier(n_estimators = 19,random_state=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AdaBoost Score: 0.933333333333\n"
     ]
    }
   ],
   "source": [
    "my_AdaBoost = AdaBoostClassifier(n_estimators = 19,random_state=2)\n",
    "my_AdaBoost.fit(X_train, y_train)\n",
    "\n",
    "y_predict = my_AdaBoost.predict(X_test)\n",
    "\n",
    "score = accuracy_score(y_test, y_predict)\n",
    "\n",
    "print('AdaBoost Score:',score)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PART F:\n",
    "Use scikit-learn “Random Forest” classifier to predict Cancer based on the training/testing \n",
    "datasets  that  you  built  in  part  (b).  Then, calculate and  report  the  accuracy  of  your \n",
    "classifier. Use this command to import and define your classifier: \n",
    "from   sklearn.ensemble    import    RandomForestClassifier\n",
    "my_RandomForest = \n",
    "RandomForestClassifier(n_estimators = 19, bootstrap = True, random_state=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AdaBoost Score: 0.955555555556\n"
     ]
    }
   ],
   "source": [
    "my_RandomForest = RandomForestClassifier(n_estimators = 19, bootstrap = True, random_state=2)\n",
    "my_RandomForest.fit(X_train, y_train)\n",
    "\n",
    "y_predict = my_RandomForest.predict(X_test)\n",
    "\n",
    "score = accuracy_score(y_test, y_predict)\n",
    "\n",
    "print('Random Forest Classifier Score:',score)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
